{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# toma de datos desde web\n",
    "# armado de dataframes\n",
    "# pandas,numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Inmuebles': ['Departamentos(3127)', 'Casas(435)', 'Locales Comerciales. Oficinas y Consultorios(325)', 'Habitaciones en Hoteles, Casas de Familias y Pensiones(207)'], 'Automotores': ['Automóviles Nacionales e Importados(633)', '4x4, Pick-up, Vans, Mini Vans, Utilitarios(84)', 'Taxis, Repuestos y Accesorios(37)', 'Planes de ahorro y Chocados(30)'], 'Empleos': ['Oficios y Ocupaciones Varias(659)', 'Choferes, Personal de Transporte y Abastecimiento, Autos(291)', 'Empleados(111)', 'Personal auxiliar de Casas Particulares. Hoteles, Clínicas(92)'], 'Servicios': ['Cuidado de Personas(469)', 'Astrología y Tarot(144)', 'Construcción y Refacciones(55)', 'Mudanzas, Fletes y Logística(55)'], 'Contactos': ['Agradecimientos(79)', 'Solos y Solas(11)', 'Mensajes y Saludos(2)', 'Sociales(1)'], 'Mix': ['Máquinas y otros materiales para industrias y negocios(36)', 'Mascotas y Animales(18)', 'Hogar y Muebles(15)', 'Boliches y Otros(12)'], 'Legales': ['Convocatorias(63)', 'Edictos Judiciales(38)', 'Avisos al Comercio(37)', 'Licitaciones(25)']}\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get(\"https://www.clasificados.clarin.com/inicio/index#!/\")\n",
    "\n",
    "titulos2=[]\n",
    "subtitulos2=[]\n",
    "listadesep=[]\n",
    "\n",
    "def functionarie(lista,listasep):\n",
    "    diccionario={}\n",
    "    for i in lista:\n",
    "        diccionario[i]=[]\n",
    "    keys=[]\n",
    "    keys.extend(diccionario.keys())\n",
    "    key=keys[0]\n",
    "    for i in listasep:\n",
    "        if i in keys:\n",
    "            key=i\n",
    "        else:\n",
    "            diccionario[key].append(i)\n",
    "    return diccionario\n",
    "        \n",
    "for i in range(1,8):\n",
    "    titulos=driver.find_element_by_xpath(\"/html/body/section[3]/section/article[2]/div/div/div[{}]/h2/a/span\".format(i))\n",
    "    #print(\"\\n ------------------------\")\n",
    "    #print(titulos.text)\n",
    "    titulos2.append(titulos.text)\n",
    "    #print(\"\\n ------------------------\")\n",
    "    listadesep.append(titulos.text)\n",
    "    for j in range(1,5):\n",
    "        subtitulos=driver.find_element_by_xpath(\"/html/body/section[3]/section/article[2]/div/div/div[{}]/ul/li[{}]\".format(i,j))\n",
    "        #print(subtitulos.text)\n",
    "        subtitulos2.append(subtitulos.text)\n",
    "        listadesep.append(subtitulos.text)\n",
    "\n",
    "\n",
    "#print(titulos2,\"\\n\",subtitulos2,\"\\n\",listadesep)\n",
    "\n",
    "diccionario=functionarie(titulos2,listadesep)\n",
    "print(diccionario)\n",
    "#print(listadesep)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oficios y Ocupaciones Varias(659)',\n",
       " 'Choferes, Personal de Transporte y Abastecimiento, Autos(291)',\n",
       " 'Empleados(111)',\n",
       " 'Personal auxiliar de Casas Particulares. Hoteles, Clínicas(92)']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario['Empleos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(diccionario,orient=\"index\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inmuebles</td>\n",
       "      <td>Departamentos(3127)</td>\n",
       "      <td>Casas(435)</td>\n",
       "      <td>Locales Comerciales. Oficinas y Consultorios(325)</td>\n",
       "      <td>Habitaciones en Hoteles, Casas de Familias y P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automotores</td>\n",
       "      <td>Automóviles Nacionales e Importados(633)</td>\n",
       "      <td>4x4, Pick-up, Vans, Mini Vans, Utilitarios(84)</td>\n",
       "      <td>Taxis, Repuestos y Accesorios(37)</td>\n",
       "      <td>Planes de ahorro y Chocados(30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Empleos</td>\n",
       "      <td>Oficios y Ocupaciones Varias(659)</td>\n",
       "      <td>Choferes, Personal de Transporte y Abastecimie...</td>\n",
       "      <td>Empleados(111)</td>\n",
       "      <td>Personal auxiliar de Casas Particulares. Hotel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Servicios</td>\n",
       "      <td>Cuidado de Personas(469)</td>\n",
       "      <td>Astrología y Tarot(144)</td>\n",
       "      <td>Construcción y Refacciones(55)</td>\n",
       "      <td>Mudanzas, Fletes y Logística(55)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Contactos</td>\n",
       "      <td>Agradecimientos(79)</td>\n",
       "      <td>Solos y Solas(11)</td>\n",
       "      <td>Mensajes y Saludos(2)</td>\n",
       "      <td>Sociales(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mix</td>\n",
       "      <td>Máquinas y otros materiales para industrias y ...</td>\n",
       "      <td>Mascotas y Animales(18)</td>\n",
       "      <td>Hogar y Muebles(15)</td>\n",
       "      <td>Boliches y Otros(12)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Legales</td>\n",
       "      <td>Convocatorias(63)</td>\n",
       "      <td>Edictos Judiciales(38)</td>\n",
       "      <td>Avisos al Comercio(37)</td>\n",
       "      <td>Licitaciones(25)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                                  0  \\\n",
       "0    Inmuebles                                Departamentos(3127)   \n",
       "1  Automotores           Automóviles Nacionales e Importados(633)   \n",
       "2      Empleos                  Oficios y Ocupaciones Varias(659)   \n",
       "3    Servicios                           Cuidado de Personas(469)   \n",
       "4    Contactos                                Agradecimientos(79)   \n",
       "5          Mix  Máquinas y otros materiales para industrias y ...   \n",
       "6      Legales                                  Convocatorias(63)   \n",
       "\n",
       "                                                   1  \\\n",
       "0                                         Casas(435)   \n",
       "1     4x4, Pick-up, Vans, Mini Vans, Utilitarios(84)   \n",
       "2  Choferes, Personal de Transporte y Abastecimie...   \n",
       "3                            Astrología y Tarot(144)   \n",
       "4                                  Solos y Solas(11)   \n",
       "5                            Mascotas y Animales(18)   \n",
       "6                             Edictos Judiciales(38)   \n",
       "\n",
       "                                                   2  \\\n",
       "0  Locales Comerciales. Oficinas y Consultorios(325)   \n",
       "1                  Taxis, Repuestos y Accesorios(37)   \n",
       "2                                     Empleados(111)   \n",
       "3                     Construcción y Refacciones(55)   \n",
       "4                              Mensajes y Saludos(2)   \n",
       "5                                Hogar y Muebles(15)   \n",
       "6                             Avisos al Comercio(37)   \n",
       "\n",
       "                                                   3  \n",
       "0  Habitaciones en Hoteles, Casas de Familias y P...  \n",
       "1                    Planes de ahorro y Chocados(30)  \n",
       "2  Personal auxiliar de Casas Particulares. Hotel...  \n",
       "3                   Mudanzas, Fletes y Logística(55)  \n",
       "4                                        Sociales(1)  \n",
       "5                               Boliches y Otros(12)  \n",
       "6                                   Licitaciones(25)  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           Casas(435)\n",
       "1       4x4, Pick-up, Vans, Mini Vans, Utilitarios(84)\n",
       "2    Choferes, Personal de Transporte y Abastecimie...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario2={\"titulos\":[],\"subtitulos\":[]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.T:\n",
    "    for j in df.T[i]:\n",
    "        diccionario2[\"titulos\"].append(df.iloc[i,0])\n",
    "        diccionario2[\"subtitulos\"].append(j)\n",
    "\n",
    "datosF=pd.DataFrame(diccionario2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=datosF.iloc[:,0:1]\n",
    "Y=datosF.iloc[:,1:]\n",
    "Y=Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 0 0 0 0 0 2 2 2 2 2 6 6 6 6 6 1 1 1 1 1 5 5 5 5 5 4 4 4 4 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stalker\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Stalker\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "x=X\n",
    "labelencoder_X=LabelEncoder()\n",
    "labelencoder_X.fit(X)\n",
    "X=labelencoder_X.transform(X)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stalker\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Stalker\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx=X.reshape(35,1).astype(\"float32\")\n",
    "onehotencoder=OneHotEncoder(categorical_features=[0])\n",
    "X=onehotencoder.fit_transform(cx).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hotear(vector):\n",
    "    yei=[]\n",
    "    yei=[x for x in one_hot(str(vector),len(vector))]\n",
    "    yei=set(yei)\n",
    "    yei=np.asarray(list(yei)).astype(\"int\")\n",
    "    return yei\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yei=one_hotear(Y)\n",
    "yei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 33\n"
     ]
    }
   ],
   "source": [
    "print(len(X),len(yei_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizar(sequences,dimension=35):\n",
    "    results=np.zeros((len(sequences),dimension))\n",
    "    for i,sequences in enumerate(sequences):\n",
    "        results[i,sequences]=1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "yei_vect=vectorizar(yei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models,layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Dense(10,activation='relu',input_shape=(35,)))\n",
    "model.add(layers.Dense(10,activation='relu'))\n",
    "model.add(layers.Dense(7,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yvei=yei_vect[:15]\n",
    "x_train=X[:15]\n",
    "yei_val=yei_vect[15:29]\n",
    "x_val=X[15:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15 samples, validate on 15 samples\n",
      "Epoch 1/250\n",
      "15/15 [==============================] - 0s 733us/step - loss: 0.3841 - acc: 0.8571 - val_loss: 0.3834 - val_acc: 0.8571\n",
      "Epoch 2/250\n",
      "15/15 [==============================] - 0s 600us/step - loss: 0.3834 - acc: 0.8571 - val_loss: 0.3827 - val_acc: 0.8571\n",
      "Epoch 3/250\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.3827 - acc: 0.8571 - val_loss: 0.3820 - val_acc: 0.8571\n",
      "Epoch 4/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3820 - acc: 0.8571 - val_loss: 0.3813 - val_acc: 0.8571\n",
      "Epoch 5/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3813 - acc: 0.8571 - val_loss: 0.3806 - val_acc: 0.8571\n",
      "Epoch 6/250\n",
      "15/15 [==============================] - 0s 133us/step - loss: 0.3806 - acc: 0.8571 - val_loss: 0.3799 - val_acc: 0.8571\n",
      "Epoch 7/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3799 - acc: 0.8571 - val_loss: 0.3792 - val_acc: 0.8571\n",
      "Epoch 8/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.3792 - acc: 0.8571 - val_loss: 0.3785 - val_acc: 0.8571\n",
      "Epoch 9/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.3785 - acc: 0.8571 - val_loss: 0.3778 - val_acc: 0.8571\n",
      "Epoch 10/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3778 - acc: 0.8571 - val_loss: 0.3771 - val_acc: 0.8571\n",
      "Epoch 11/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.3771 - acc: 0.8571 - val_loss: 0.3764 - val_acc: 0.8571\n",
      "Epoch 12/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3764 - acc: 0.8571 - val_loss: 0.3756 - val_acc: 0.8571\n",
      "Epoch 13/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3756 - acc: 0.8571 - val_loss: 0.3749 - val_acc: 0.8571\n",
      "Epoch 14/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.3749 - acc: 0.8571 - val_loss: 0.3741 - val_acc: 0.8571\n",
      "Epoch 15/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3741 - acc: 0.8571 - val_loss: 0.3734 - val_acc: 0.8571\n",
      "Epoch 16/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3734 - acc: 0.8571 - val_loss: 0.3726 - val_acc: 0.8571\n",
      "Epoch 17/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3726 - acc: 0.8571 - val_loss: 0.3718 - val_acc: 0.8571\n",
      "Epoch 18/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.3718 - acc: 0.8571 - val_loss: 0.3710 - val_acc: 0.8571\n",
      "Epoch 19/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.3710 - acc: 0.8571 - val_loss: 0.3702 - val_acc: 0.8571\n",
      "Epoch 20/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3702 - acc: 0.8571 - val_loss: 0.3694 - val_acc: 0.8571\n",
      "Epoch 21/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3694 - acc: 0.8571 - val_loss: 0.3685 - val_acc: 0.8571\n",
      "Epoch 22/250\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3685 - acc: 0.8571 - val_loss: 0.3677 - val_acc: 0.8571\n",
      "Epoch 23/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3677 - acc: 0.8571 - val_loss: 0.3668 - val_acc: 0.8571\n",
      "Epoch 24/250\n",
      "15/15 [==============================] - 0s 667us/step - loss: 0.3668 - acc: 0.8571 - val_loss: 0.3660 - val_acc: 0.8571\n",
      "Epoch 25/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3660 - acc: 0.8571 - val_loss: 0.3651 - val_acc: 0.8571\n",
      "Epoch 26/250\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.3651 - acc: 0.8571 - val_loss: 0.3642 - val_acc: 0.8571\n",
      "Epoch 27/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3642 - acc: 0.8571 - val_loss: 0.3634 - val_acc: 0.8571\n",
      "Epoch 28/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3634 - acc: 0.8571 - val_loss: 0.3625 - val_acc: 0.8571\n",
      "Epoch 29/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3625 - acc: 0.8571 - val_loss: 0.3616 - val_acc: 0.8571\n",
      "Epoch 30/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3616 - acc: 0.8571 - val_loss: 0.3607 - val_acc: 0.8571\n",
      "Epoch 31/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3607 - acc: 0.8571 - val_loss: 0.3598 - val_acc: 0.8571\n",
      "Epoch 32/250\n",
      "15/15 [==============================] - 0s 733us/step - loss: 0.3598 - acc: 0.8571 - val_loss: 0.3588 - val_acc: 0.8571\n",
      "Epoch 33/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.3588 - acc: 0.8571 - val_loss: 0.3579 - val_acc: 0.8571\n",
      "Epoch 34/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3579 - acc: 0.8571 - val_loss: 0.3569 - val_acc: 0.8571\n",
      "Epoch 35/250\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.3569 - acc: 0.8571 - val_loss: 0.3559 - val_acc: 0.8571\n",
      "Epoch 36/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3559 - acc: 0.8571 - val_loss: 0.3550 - val_acc: 0.8571\n",
      "Epoch 37/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.3550 - acc: 0.8571 - val_loss: 0.3540 - val_acc: 0.8571\n",
      "Epoch 38/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3540 - acc: 0.8571 - val_loss: 0.3530 - val_acc: 0.8571\n",
      "Epoch 39/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3530 - acc: 0.8571 - val_loss: 0.3520 - val_acc: 0.8571\n",
      "Epoch 40/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3520 - acc: 0.8571 - val_loss: 0.3510 - val_acc: 0.8571\n",
      "Epoch 41/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3510 - acc: 0.8571 - val_loss: 0.3500 - val_acc: 0.8571\n",
      "Epoch 42/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3500 - acc: 0.8571 - val_loss: 0.3490 - val_acc: 0.8571\n",
      "Epoch 43/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3490 - acc: 0.8571 - val_loss: 0.3480 - val_acc: 0.8571\n",
      "Epoch 44/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3480 - acc: 0.8571 - val_loss: 0.3469 - val_acc: 0.8571\n",
      "Epoch 45/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3469 - acc: 0.8571 - val_loss: 0.3459 - val_acc: 0.8571\n",
      "Epoch 46/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3459 - acc: 0.8571 - val_loss: 0.3449 - val_acc: 0.8571\n",
      "Epoch 47/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3449 - acc: 0.8571 - val_loss: 0.3438 - val_acc: 0.8571\n",
      "Epoch 48/250\n",
      "15/15 [==============================] - 0s 600us/step - loss: 0.3438 - acc: 0.8571 - val_loss: 0.3428 - val_acc: 0.8571\n",
      "Epoch 49/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.3428 - acc: 0.8571 - val_loss: 0.3417 - val_acc: 0.8571\n",
      "Epoch 50/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3417 - acc: 0.8571 - val_loss: 0.3406 - val_acc: 0.8571\n",
      "Epoch 51/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.3406 - acc: 0.8571 - val_loss: 0.3396 - val_acc: 0.8571\n",
      "Epoch 52/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3396 - acc: 0.8571 - val_loss: 0.3385 - val_acc: 0.8571\n",
      "Epoch 53/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3385 - acc: 0.8571 - val_loss: 0.3374 - val_acc: 0.8571\n",
      "Epoch 54/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.3374 - acc: 0.8571 - val_loss: 0.3363 - val_acc: 0.8571\n",
      "Epoch 55/250\n",
      "15/15 [==============================] - 0s 600us/step - loss: 0.3363 - acc: 0.8571 - val_loss: 0.3352 - val_acc: 0.8571\n",
      "Epoch 56/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.3352 - acc: 0.8571 - val_loss: 0.3341 - val_acc: 0.8571\n",
      "Epoch 57/250\n",
      "15/15 [==============================] - 0s 133us/step - loss: 0.3341 - acc: 0.8571 - val_loss: 0.3330 - val_acc: 0.8571\n",
      "Epoch 58/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3330 - acc: 0.8571 - val_loss: 0.3318 - val_acc: 0.8571\n",
      "Epoch 59/250\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.3318 - acc: 0.8571 - val_loss: 0.3307 - val_acc: 0.8571\n",
      "Epoch 60/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3307 - acc: 0.8571 - val_loss: 0.3296 - val_acc: 0.8571\n",
      "Epoch 61/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3296 - acc: 0.8571 - val_loss: 0.3284 - val_acc: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.3284 - acc: 0.8571 - val_loss: 0.3272 - val_acc: 0.8571\n",
      "Epoch 63/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3272 - acc: 0.8571 - val_loss: 0.3261 - val_acc: 0.8571\n",
      "Epoch 64/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3261 - acc: 0.8571 - val_loss: 0.3249 - val_acc: 0.8571\n",
      "Epoch 65/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3249 - acc: 0.8571 - val_loss: 0.3237 - val_acc: 0.8571\n",
      "Epoch 66/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3237 - acc: 0.8571 - val_loss: 0.3225 - val_acc: 0.8571\n",
      "Epoch 67/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3225 - acc: 0.8571 - val_loss: 0.3214 - val_acc: 0.8571\n",
      "Epoch 68/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3214 - acc: 0.8571 - val_loss: 0.3202 - val_acc: 0.8571\n",
      "Epoch 69/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3202 - acc: 0.8571 - val_loss: 0.3189 - val_acc: 0.8571\n",
      "Epoch 70/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.3189 - acc: 0.8571 - val_loss: 0.3177 - val_acc: 0.8571\n",
      "Epoch 71/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.3177 - acc: 0.8571 - val_loss: 0.3165 - val_acc: 0.8571\n",
      "Epoch 72/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.3165 - acc: 0.8571 - val_loss: 0.3152 - val_acc: 0.8571\n",
      "Epoch 73/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3152 - acc: 0.8571 - val_loss: 0.3139 - val_acc: 0.8571\n",
      "Epoch 74/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3139 - acc: 0.8571 - val_loss: 0.3126 - val_acc: 0.8571\n",
      "Epoch 75/250\n",
      "15/15 [==============================] - 0s 600us/step - loss: 0.3126 - acc: 0.8571 - val_loss: 0.3113 - val_acc: 0.8571\n",
      "Epoch 76/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3113 - acc: 0.8571 - val_loss: 0.3099 - val_acc: 0.8571\n",
      "Epoch 77/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3099 - acc: 0.8571 - val_loss: 0.3086 - val_acc: 0.8571\n",
      "Epoch 78/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3086 - acc: 0.8571 - val_loss: 0.3072 - val_acc: 0.8571\n",
      "Epoch 79/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3072 - acc: 0.8571 - val_loss: 0.3058 - val_acc: 0.8667\n",
      "Epoch 80/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3058 - acc: 0.8667 - val_loss: 0.3045 - val_acc: 0.8667\n",
      "Epoch 81/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3045 - acc: 0.8667 - val_loss: 0.3031 - val_acc: 0.8667\n",
      "Epoch 82/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3031 - acc: 0.8667 - val_loss: 0.3017 - val_acc: 0.8667\n",
      "Epoch 83/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.3017 - acc: 0.8667 - val_loss: 0.3003 - val_acc: 0.8667\n",
      "Epoch 84/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.3003 - acc: 0.8667 - val_loss: 0.2990 - val_acc: 0.8667\n",
      "Epoch 85/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.2990 - acc: 0.8667 - val_loss: 0.2976 - val_acc: 0.8667\n",
      "Epoch 86/250\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2976 - acc: 0.8667 - val_loss: 0.2962 - val_acc: 0.8667\n",
      "Epoch 87/250\n",
      "15/15 [==============================] - 0s 667us/step - loss: 0.2962 - acc: 0.8667 - val_loss: 0.2947 - val_acc: 0.8667\n",
      "Epoch 88/250\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.2947 - acc: 0.8667 - val_loss: 0.2933 - val_acc: 0.8667\n",
      "Epoch 89/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2933 - acc: 0.8667 - val_loss: 0.2918 - val_acc: 0.8667\n",
      "Epoch 90/250\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.2918 - acc: 0.8667 - val_loss: 0.2903 - val_acc: 0.8667\n",
      "Epoch 91/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2903 - acc: 0.8667 - val_loss: 0.2888 - val_acc: 0.8667\n",
      "Epoch 92/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.2888 - acc: 0.8667 - val_loss: 0.2873 - val_acc: 0.8667\n",
      "Epoch 93/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.2873 - acc: 0.8667 - val_loss: 0.2858 - val_acc: 0.8667\n",
      "Epoch 94/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.2858 - acc: 0.8667 - val_loss: 0.2842 - val_acc: 0.8667\n",
      "Epoch 95/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2842 - acc: 0.8667 - val_loss: 0.2826 - val_acc: 0.8667\n",
      "Epoch 96/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2826 - acc: 0.8667 - val_loss: 0.2810 - val_acc: 0.8667\n",
      "Epoch 97/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2810 - acc: 0.8667 - val_loss: 0.2794 - val_acc: 0.8667\n",
      "Epoch 98/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2794 - acc: 0.8667 - val_loss: 0.2778 - val_acc: 0.8667\n",
      "Epoch 99/250\n",
      "15/15 [==============================] - 0s 133us/step - loss: 0.2778 - acc: 0.8667 - val_loss: 0.2762 - val_acc: 0.8667\n",
      "Epoch 100/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2762 - acc: 0.8667 - val_loss: 0.2745 - val_acc: 0.8667\n",
      "Epoch 101/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2745 - acc: 0.8667 - val_loss: 0.2729 - val_acc: 0.8667\n",
      "Epoch 102/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.2729 - acc: 0.8667 - val_loss: 0.2713 - val_acc: 0.8667\n",
      "Epoch 103/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2713 - acc: 0.8667 - val_loss: 0.2696 - val_acc: 0.8762\n",
      "Epoch 104/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2696 - acc: 0.8762 - val_loss: 0.2679 - val_acc: 0.8762\n",
      "Epoch 105/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2679 - acc: 0.8762 - val_loss: 0.2663 - val_acc: 0.8857\n",
      "Epoch 106/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2663 - acc: 0.8857 - val_loss: 0.2646 - val_acc: 0.8857\n",
      "Epoch 107/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.2646 - acc: 0.8857 - val_loss: 0.2629 - val_acc: 0.8857\n",
      "Epoch 108/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2629 - acc: 0.8857 - val_loss: 0.2612 - val_acc: 0.8857\n",
      "Epoch 109/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2612 - acc: 0.8857 - val_loss: 0.2596 - val_acc: 0.8857\n",
      "Epoch 110/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2596 - acc: 0.8857 - val_loss: 0.2579 - val_acc: 0.8857\n",
      "Epoch 111/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2579 - acc: 0.8857 - val_loss: 0.2562 - val_acc: 0.8857\n",
      "Epoch 112/250\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2562 - acc: 0.8857 - val_loss: 0.2545 - val_acc: 0.8857\n",
      "Epoch 113/250\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.2545 - acc: 0.8857 - val_loss: 0.2528 - val_acc: 0.8857\n",
      "Epoch 114/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2528 - acc: 0.8857 - val_loss: 0.2511 - val_acc: 0.8857\n",
      "Epoch 115/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.2511 - acc: 0.8857 - val_loss: 0.2494 - val_acc: 0.8857\n",
      "Epoch 116/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2494 - acc: 0.8857 - val_loss: 0.2477 - val_acc: 0.8857\n",
      "Epoch 117/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2477 - acc: 0.8857 - val_loss: 0.2460 - val_acc: 0.8857\n",
      "Epoch 118/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.2460 - acc: 0.8857 - val_loss: 0.2443 - val_acc: 0.8857\n",
      "Epoch 119/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.2443 - acc: 0.8857 - val_loss: 0.2425 - val_acc: 0.8952\n",
      "Epoch 120/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.2425 - acc: 0.8952 - val_loss: 0.2408 - val_acc: 0.9048\n",
      "Epoch 121/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.2408 - acc: 0.9048 - val_loss: 0.2390 - val_acc: 0.9048\n",
      "Epoch 122/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2390 - acc: 0.9048 - val_loss: 0.2373 - val_acc: 0.9048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2373 - acc: 0.9048 - val_loss: 0.2356 - val_acc: 0.9048\n",
      "Epoch 124/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.2356 - acc: 0.9048 - val_loss: 0.2339 - val_acc: 0.9048\n",
      "Epoch 125/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2339 - acc: 0.9048 - val_loss: 0.2322 - val_acc: 0.9048\n",
      "Epoch 126/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.2322 - acc: 0.9048 - val_loss: 0.2305 - val_acc: 0.9048\n",
      "Epoch 127/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.2305 - acc: 0.9048 - val_loss: 0.2288 - val_acc: 0.9048\n",
      "Epoch 128/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2288 - acc: 0.9048 - val_loss: 0.2271 - val_acc: 0.9048\n",
      "Epoch 129/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2271 - acc: 0.9048 - val_loss: 0.2254 - val_acc: 0.9048\n",
      "Epoch 130/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.2254 - acc: 0.9048 - val_loss: 0.2237 - val_acc: 0.9048\n",
      "Epoch 131/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2237 - acc: 0.9048 - val_loss: 0.2220 - val_acc: 0.9048\n",
      "Epoch 132/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.2220 - acc: 0.9048 - val_loss: 0.2204 - val_acc: 0.9048\n",
      "Epoch 133/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2204 - acc: 0.9048 - val_loss: 0.2187 - val_acc: 0.9048\n",
      "Epoch 134/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2187 - acc: 0.9048 - val_loss: 0.2171 - val_acc: 0.9048\n",
      "Epoch 135/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2171 - acc: 0.9048 - val_loss: 0.2155 - val_acc: 0.9048\n",
      "Epoch 136/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2155 - acc: 0.9048 - val_loss: 0.2138 - val_acc: 0.9048\n",
      "Epoch 137/250\n",
      "15/15 [==============================] - 0s 600us/step - loss: 0.2138 - acc: 0.9048 - val_loss: 0.2122 - val_acc: 0.9048\n",
      "Epoch 138/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2122 - acc: 0.9048 - val_loss: 0.2106 - val_acc: 0.9048\n",
      "Epoch 139/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2106 - acc: 0.9048 - val_loss: 0.2090 - val_acc: 0.9048\n",
      "Epoch 140/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.2090 - acc: 0.9048 - val_loss: 0.2075 - val_acc: 0.9048\n",
      "Epoch 141/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2075 - acc: 0.9048 - val_loss: 0.2059 - val_acc: 0.9048\n",
      "Epoch 142/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.2059 - acc: 0.9048 - val_loss: 0.2043 - val_acc: 0.9048\n",
      "Epoch 143/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.2043 - acc: 0.9048 - val_loss: 0.2028 - val_acc: 0.9048\n",
      "Epoch 144/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.2028 - acc: 0.9048 - val_loss: 0.2013 - val_acc: 0.9048\n",
      "Epoch 145/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.2013 - acc: 0.9048 - val_loss: 0.1998 - val_acc: 0.9048\n",
      "Epoch 146/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1998 - acc: 0.9048 - val_loss: 0.1983 - val_acc: 0.9048\n",
      "Epoch 147/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1983 - acc: 0.9048 - val_loss: 0.1968 - val_acc: 0.9048\n",
      "Epoch 148/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1968 - acc: 0.9048 - val_loss: 0.1953 - val_acc: 0.9048\n",
      "Epoch 149/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1953 - acc: 0.9048 - val_loss: 0.1939 - val_acc: 0.9048\n",
      "Epoch 150/250\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.1939 - acc: 0.9048 - val_loss: 0.1925 - val_acc: 0.9048\n",
      "Epoch 151/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1925 - acc: 0.9048 - val_loss: 0.1911 - val_acc: 0.9048\n",
      "Epoch 152/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.1911 - acc: 0.9048 - val_loss: 0.1897 - val_acc: 0.9048\n",
      "Epoch 153/250\n",
      "15/15 [==============================] - 0s 667us/step - loss: 0.1897 - acc: 0.9048 - val_loss: 0.1883 - val_acc: 0.9048\n",
      "Epoch 154/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1883 - acc: 0.9048 - val_loss: 0.1869 - val_acc: 0.9048\n",
      "Epoch 155/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1869 - acc: 0.9048 - val_loss: 0.1855 - val_acc: 0.9048\n",
      "Epoch 156/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1855 - acc: 0.9048 - val_loss: 0.1842 - val_acc: 0.9143\n",
      "Epoch 157/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1842 - acc: 0.9143 - val_loss: 0.1829 - val_acc: 0.9143\n",
      "Epoch 158/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1829 - acc: 0.9143 - val_loss: 0.1815 - val_acc: 0.9143\n",
      "Epoch 159/250\n",
      "15/15 [==============================] - 0s 733us/step - loss: 0.1815 - acc: 0.9143 - val_loss: 0.1802 - val_acc: 0.9143\n",
      "Epoch 160/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1802 - acc: 0.9143 - val_loss: 0.1789 - val_acc: 0.9143\n",
      "Epoch 161/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.1789 - acc: 0.9143 - val_loss: 0.1776 - val_acc: 0.9143\n",
      "Epoch 162/250\n",
      "15/15 [==============================] - 0s 733us/step - loss: 0.1776 - acc: 0.9143 - val_loss: 0.1763 - val_acc: 0.9143\n",
      "Epoch 163/250\n",
      "15/15 [==============================] - 0s 667us/step - loss: 0.1763 - acc: 0.9143 - val_loss: 0.1750 - val_acc: 0.9143\n",
      "Epoch 164/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1750 - acc: 0.9143 - val_loss: 0.1737 - val_acc: 0.9143\n",
      "Epoch 165/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1737 - acc: 0.9143 - val_loss: 0.1724 - val_acc: 0.9143\n",
      "Epoch 166/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1724 - acc: 0.9143 - val_loss: 0.1711 - val_acc: 0.9143\n",
      "Epoch 167/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1711 - acc: 0.9143 - val_loss: 0.1698 - val_acc: 0.9048\n",
      "Epoch 168/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1698 - acc: 0.9048 - val_loss: 0.1686 - val_acc: 0.9048\n",
      "Epoch 169/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1686 - acc: 0.9048 - val_loss: 0.1673 - val_acc: 0.9048\n",
      "Epoch 170/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.1673 - acc: 0.9048 - val_loss: 0.1661 - val_acc: 0.9048\n",
      "Epoch 171/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1661 - acc: 0.9048 - val_loss: 0.1649 - val_acc: 0.9048\n",
      "Epoch 172/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.1649 - acc: 0.9048 - val_loss: 0.1637 - val_acc: 0.9048\n",
      "Epoch 173/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1637 - acc: 0.9048 - val_loss: 0.1625 - val_acc: 0.9048\n",
      "Epoch 174/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1625 - acc: 0.9048 - val_loss: 0.1612 - val_acc: 0.9048\n",
      "Epoch 175/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.1612 - acc: 0.9048 - val_loss: 0.1601 - val_acc: 0.9048\n",
      "Epoch 176/250\n",
      "15/15 [==============================] - 0s 600us/step - loss: 0.1601 - acc: 0.9048 - val_loss: 0.1589 - val_acc: 0.9143\n",
      "Epoch 177/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.1589 - acc: 0.9143 - val_loss: 0.1577 - val_acc: 0.9143\n",
      "Epoch 178/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1577 - acc: 0.9143 - val_loss: 0.1565 - val_acc: 0.9238\n",
      "Epoch 179/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.1565 - acc: 0.9238 - val_loss: 0.1554 - val_acc: 0.9238\n",
      "Epoch 180/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1554 - acc: 0.9238 - val_loss: 0.1542 - val_acc: 0.9238\n",
      "Epoch 181/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.1542 - acc: 0.9238 - val_loss: 0.1531 - val_acc: 0.9238\n",
      "Epoch 182/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1531 - acc: 0.9238 - val_loss: 0.1519 - val_acc: 0.9238\n",
      "Epoch 183/250\n",
      "15/15 [==============================] - 0s 933us/step - loss: 0.1519 - acc: 0.9238 - val_loss: 0.1508 - val_acc: 0.9238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1508 - acc: 0.9238 - val_loss: 0.1497 - val_acc: 0.9333\n",
      "Epoch 185/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1497 - acc: 0.9333 - val_loss: 0.1486 - val_acc: 0.9333\n",
      "Epoch 186/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1486 - acc: 0.9333 - val_loss: 0.1475 - val_acc: 0.9333\n",
      "Epoch 187/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1475 - acc: 0.9333 - val_loss: 0.1464 - val_acc: 0.9429\n",
      "Epoch 188/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1464 - acc: 0.9429 - val_loss: 0.1453 - val_acc: 0.9524\n",
      "Epoch 189/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1453 - acc: 0.9524 - val_loss: 0.1442 - val_acc: 0.9524\n",
      "Epoch 190/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1442 - acc: 0.9524 - val_loss: 0.1431 - val_acc: 0.9524\n",
      "Epoch 191/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1431 - acc: 0.9524 - val_loss: 0.1420 - val_acc: 0.9524\n",
      "Epoch 192/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1420 - acc: 0.9524 - val_loss: 0.1408 - val_acc: 0.9524\n",
      "Epoch 193/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1408 - acc: 0.9524 - val_loss: 0.1397 - val_acc: 0.9524\n",
      "Epoch 194/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1397 - acc: 0.9524 - val_loss: 0.1386 - val_acc: 0.9524\n",
      "Epoch 195/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1386 - acc: 0.9524 - val_loss: 0.1375 - val_acc: 0.9524\n",
      "Epoch 196/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1375 - acc: 0.9524 - val_loss: 0.1365 - val_acc: 0.9524\n",
      "Epoch 197/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1365 - acc: 0.9524 - val_loss: 0.1354 - val_acc: 0.9524\n",
      "Epoch 198/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1354 - acc: 0.9524 - val_loss: 0.1343 - val_acc: 0.9524\n",
      "Epoch 199/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1343 - acc: 0.9524 - val_loss: 0.1332 - val_acc: 0.9524\n",
      "Epoch 200/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1332 - acc: 0.9524 - val_loss: 0.1322 - val_acc: 0.9524\n",
      "Epoch 201/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1322 - acc: 0.9524 - val_loss: 0.1312 - val_acc: 0.9524\n",
      "Epoch 202/250\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1312 - acc: 0.9524 - val_loss: 0.1301 - val_acc: 0.9524\n",
      "Epoch 203/250\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1301 - acc: 0.9524 - val_loss: 0.1291 - val_acc: 0.9524\n",
      "Epoch 204/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.1291 - acc: 0.9524 - val_loss: 0.1281 - val_acc: 0.9524\n",
      "Epoch 205/250\n",
      "15/15 [==============================] - 0s 667us/step - loss: 0.1281 - acc: 0.9524 - val_loss: 0.1270 - val_acc: 0.9524\n",
      "Epoch 206/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1270 - acc: 0.9524 - val_loss: 0.1260 - val_acc: 0.9524\n",
      "Epoch 207/250\n",
      "15/15 [==============================] - 0s 733us/step - loss: 0.1260 - acc: 0.9524 - val_loss: 0.1250 - val_acc: 0.9524\n",
      "Epoch 208/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1250 - acc: 0.9524 - val_loss: 0.1240 - val_acc: 0.9524\n",
      "Epoch 209/250\n",
      "15/15 [==============================] - 0s 667us/step - loss: 0.1240 - acc: 0.9524 - val_loss: 0.1230 - val_acc: 0.9524\n",
      "Epoch 210/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.1230 - acc: 0.9524 - val_loss: 0.1220 - val_acc: 0.9524\n",
      "Epoch 211/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1220 - acc: 0.9524 - val_loss: 0.1209 - val_acc: 0.9524\n",
      "Epoch 212/250\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1209 - acc: 0.9524 - val_loss: 0.1199 - val_acc: 0.9619\n",
      "Epoch 213/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.1199 - acc: 0.9619 - val_loss: 0.1189 - val_acc: 0.9619\n",
      "Epoch 214/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1189 - acc: 0.9619 - val_loss: 0.1179 - val_acc: 0.9619\n",
      "Epoch 215/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1179 - acc: 0.9619 - val_loss: 0.1168 - val_acc: 0.9619\n",
      "Epoch 216/250\n",
      "15/15 [==============================] - 0s 667us/step - loss: 0.1168 - acc: 0.9619 - val_loss: 0.1158 - val_acc: 0.9619\n",
      "Epoch 217/250\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.1158 - acc: 0.9619 - val_loss: 0.1148 - val_acc: 0.9619\n",
      "Epoch 218/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.1148 - acc: 0.9619 - val_loss: 0.1138 - val_acc: 0.9619\n",
      "Epoch 219/250\n",
      "15/15 [==============================] - 0s 600us/step - loss: 0.1138 - acc: 0.9619 - val_loss: 0.1128 - val_acc: 0.9619\n",
      "Epoch 220/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1128 - acc: 0.9619 - val_loss: 0.1118 - val_acc: 0.9619\n",
      "Epoch 221/250\n",
      "15/15 [==============================] - 0s 600us/step - loss: 0.1118 - acc: 0.9619 - val_loss: 0.1108 - val_acc: 0.9619\n",
      "Epoch 222/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.1108 - acc: 0.9619 - val_loss: 0.1099 - val_acc: 0.9619\n",
      "Epoch 223/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1099 - acc: 0.9619 - val_loss: 0.1089 - val_acc: 0.9619\n",
      "Epoch 224/250\n",
      "15/15 [==============================] - 0s 600us/step - loss: 0.1089 - acc: 0.9619 - val_loss: 0.1079 - val_acc: 0.9619\n",
      "Epoch 225/250\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.1079 - acc: 0.9619 - val_loss: 0.1069 - val_acc: 0.9619\n",
      "Epoch 226/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1069 - acc: 0.9619 - val_loss: 0.1059 - val_acc: 0.9619\n",
      "Epoch 227/250\n",
      "15/15 [==============================] - 0s 733us/step - loss: 0.1059 - acc: 0.9619 - val_loss: 0.1049 - val_acc: 0.9619\n",
      "Epoch 228/250\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1049 - acc: 0.9619 - val_loss: 0.1039 - val_acc: 0.9619\n",
      "Epoch 229/250\n",
      "15/15 [==============================] - 0s 733us/step - loss: 0.1039 - acc: 0.9619 - val_loss: 0.1028 - val_acc: 0.9619\n",
      "Epoch 230/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.1028 - acc: 0.9619 - val_loss: 0.1018 - val_acc: 0.9619\n",
      "Epoch 231/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1018 - acc: 0.9619 - val_loss: 0.1007 - val_acc: 0.9619\n",
      "Epoch 232/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.1007 - acc: 0.9619 - val_loss: 0.0996 - val_acc: 0.9619\n",
      "Epoch 233/250\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0996 - acc: 0.9619 - val_loss: 0.0986 - val_acc: 0.9619\n",
      "Epoch 234/250\n",
      "15/15 [==============================] - 0s 667us/step - loss: 0.0986 - acc: 0.9619 - val_loss: 0.0975 - val_acc: 0.9619\n",
      "Epoch 235/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.0975 - acc: 0.9619 - val_loss: 0.0965 - val_acc: 0.9619\n",
      "Epoch 236/250\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.0965 - acc: 0.9619 - val_loss: 0.0954 - val_acc: 0.9714\n",
      "Epoch 237/250\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.0954 - acc: 0.9714 - val_loss: 0.0943 - val_acc: 0.9714\n",
      "Epoch 238/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.0943 - acc: 0.9714 - val_loss: 0.0933 - val_acc: 0.9714\n",
      "Epoch 239/250\n",
      "15/15 [==============================] - 0s 733us/step - loss: 0.0933 - acc: 0.9714 - val_loss: 0.0922 - val_acc: 0.9714\n",
      "Epoch 240/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.0922 - acc: 0.9714 - val_loss: 0.0912 - val_acc: 0.9810\n",
      "Epoch 241/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.0912 - acc: 0.9810 - val_loss: 0.0902 - val_acc: 0.9810\n",
      "Epoch 242/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.0902 - acc: 0.9810 - val_loss: 0.0891 - val_acc: 0.9810\n",
      "Epoch 243/250\n",
      "15/15 [==============================] - 0s 600us/step - loss: 0.0891 - acc: 0.9810 - val_loss: 0.0880 - val_acc: 0.9810\n",
      "Epoch 244/250\n",
      "15/15 [==============================] - 0s 600us/step - loss: 0.0880 - acc: 0.9810 - val_loss: 0.0869 - val_acc: 0.9810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.0869 - acc: 0.9810 - val_loss: 0.0859 - val_acc: 0.9810\n",
      "Epoch 246/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.0859 - acc: 0.9810 - val_loss: 0.0848 - val_acc: 0.9810\n",
      "Epoch 247/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.0848 - acc: 0.9810 - val_loss: 0.0837 - val_acc: 0.9810\n",
      "Epoch 248/250\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.0837 - acc: 0.9810 - val_loss: 0.0827 - val_acc: 0.9810\n",
      "Epoch 249/250\n",
      "15/15 [==============================] - 0s 200us/step - loss: 0.0827 - acc: 0.9810 - val_loss: 0.0817 - val_acc: 0.9810\n",
      "Epoch 250/250\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0817 - acc: 0.9810 - val_loss: 0.0806 - val_acc: 0.9905\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(Yvei,x_train,epochs=250,batch_size=512,validation_data=(Yvei,x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(yei_vect[5].reshape(35,-1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc=history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "epochs=range(1,len(acc)+1)\n",
    "plt.plot(epochs,loss,'bo',label='Training loss')\n",
    "plt.plot(epochs,val_loss,'b',label=\"Validation loss\")\n",
    "plt.title('Training and accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "toastdata=pd.read_csv(\"test_clarin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulos</th>\n",
       "      <th>subtitulos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inmuebles</td>\n",
       "      <td>Automotores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inmuebles</td>\n",
       "      <td>Repuestos y Accesorios para Autos. Sistemas de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inmuebles</td>\n",
       "      <td>Transporte de Carga, Camiones, Acoplados, Cole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inmuebles</td>\n",
       "      <td>Autos de Colección(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inmuebles</td>\n",
       "      <td>Náutica, Aviación, Casas Rodantes, Motorhomes....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Automotores</td>\n",
       "      <td>Empleos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Automotores</td>\n",
       "      <td>Empleados, Vendedores, Ejecutivos de Cuentas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Automotores</td>\n",
       "      <td>Profesionales y Ejecutivos(72)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Automotores</td>\n",
       "      <td>Enseñanza, Capacitación, Cursos y Docentes(27)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Automotores</td>\n",
       "      <td>Electrónicos. Comunicaciones, Mecánicos, Quími...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Empleos</td>\n",
       "      <td>Servicios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Empleos</td>\n",
       "      <td>Servicios Automotores y Choferes(39)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Empleos</td>\n",
       "      <td>Negocios y Socios(34)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Empleos</td>\n",
       "      <td>Salud(20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Empleos</td>\n",
       "      <td>Legales(17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Servicios</td>\n",
       "      <td>Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Servicios</td>\n",
       "      <td>Sex shops(12)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Servicios</td>\n",
       "      <td>Ofertas, Trueques y Permutas(9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Servicios</td>\n",
       "      <td>Indumentaria y Accesorios(6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Servicios</td>\n",
       "      <td>Máquinas de coser, overlock y de tejer(5)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        titulos                                         subtitulos\n",
       "0     Inmuebles                                        Automotores\n",
       "1     Inmuebles  Repuestos y Accesorios para Autos. Sistemas de...\n",
       "2     Inmuebles  Transporte de Carga, Camiones, Acoplados, Cole...\n",
       "3     Inmuebles                              Autos de Colección(2)\n",
       "4     Inmuebles  Náutica, Aviación, Casas Rodantes, Motorhomes....\n",
       "5   Automotores                                            Empleos\n",
       "6   Automotores  Empleados, Vendedores, Ejecutivos de Cuentas, ...\n",
       "7   Automotores                     Profesionales y Ejecutivos(72)\n",
       "8   Automotores     Enseñanza, Capacitación, Cursos y Docentes(27)\n",
       "9   Automotores  Electrónicos. Comunicaciones, Mecánicos, Quími...\n",
       "10      Empleos                                          Servicios\n",
       "11      Empleos               Servicios Automotores y Choferes(39)\n",
       "12      Empleos                              Negocios y Socios(34)\n",
       "13      Empleos                                          Salud(20)\n",
       "14      Empleos                                        Legales(17)\n",
       "15    Servicios                                                Mix\n",
       "16    Servicios                                      Sex shops(12)\n",
       "17    Servicios                    Ofertas, Trueques y Permutas(9)\n",
       "18    Servicios                       Indumentaria y Accesorios(6)\n",
       "19    Servicios          Máquinas de coser, overlock y de tejer(5)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario3={\"titulos\":[],\"subtitulos\":[]}\n",
    "for i in toastdata.T:\n",
    "    for j in toastdata.T[i]:\n",
    "        diccionario3[\"titulos\"].append(df.iloc[i,0])\n",
    "        diccionario3[\"subtitulos\"].append(j)\n",
    "\n",
    "datosT=pd.DataFrame(diccionario3)\n",
    "datosT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest=datosT.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest=ytest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest=one_hotear(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest=vectorizar(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(ytest[16].reshape(35,-1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
